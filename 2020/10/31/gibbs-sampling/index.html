<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#020261"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#020261">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.23.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="MotivationIn many inference tasks, it is necessary to integrate out variables. However, this may not always be possible as the integral may not be an analytically trackable function. Thankfully, we ca">
<meta property="og:type" content="article">
<meta property="og:title" content="Gibbs Sampling">
<meta property="og:url" content="http://example.com/2020/10/31/gibbs-sampling/index.html">
<meta property="og:site_name" content="Efficient Corner">
<meta property="og:description" content="MotivationIn many inference tasks, it is necessary to integrate out variables. However, this may not always be possible as the integral may not be an analytically trackable function. Thankfully, we ca">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/gibbs_1.png">
<meta property="og:image" content="http://example.com/images/gibbs_2.png">
<meta property="og:image" content="http://example.com/images/gibbs_3.png">
<meta property="article:published_time" content="2020-10-31T13:49:55.000Z">
<meta property="article:modified_time" content="2025-04-04T02:15:41.421Z">
<meta property="article:author" content="Andy Cai">
<meta property="article:tag" content="Data science">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/gibbs_1.png">


<link rel="canonical" href="http://example.com/2020/10/31/gibbs-sampling/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2020/10/31/gibbs-sampling/","path":"2020/10/31/gibbs-sampling/","title":"Gibbs Sampling"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Gibbs Sampling | Efficient Corner</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.36/fancybox/fancybox.umd.js" integrity="sha256-hiUEBwFEpLF6DlB8sGXlKo4kPZ46Ui4qGpd0vrVkOm4=" crossorigin="anonymous" defer></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  



  <script src="/js/third-party/fancybox.js" defer></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Efficient Corner</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Condensation of experiences</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-photos"><a href="/Photos/" rel="section"><i class="fa fa-camera fa-fw"></i>photos</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation"><span class="nav-number">1.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gibbs-Sampling-method"><span class="nav-number">2.</span> <span class="nav-text">Gibbs Sampling method</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code"><span class="nav-number">3.</span> <span class="nav-text">Code</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Function-to-visualise-a-Guassian-with-a-given-variance"><span class="nav-number">4.</span> <span class="nav-text">Function to visualise a Guassian with a given variance</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-Gibbs-sampler-to-sample-from-the-2D-Gaussian"><span class="nav-number">5.</span> <span class="nav-text">The Gibbs sampler to sample from the 2D Gaussian</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Function-to-sample-from-the-3-dimensional-Gaussian"><span class="nav-number">6.</span> <span class="nav-text">Function to sample from the 3 dimensional Gaussian</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Interpretation-of-results-and-conclusion"><span class="nav-number">7.</span> <span class="nav-text">Interpretation of results and conclusion</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Andy Cai</p>
  <div class="site-description" itemprop="description">A quantitative portfolio manager passionate about dissecting complexity at the intersection of finance, math, and technology. This site is my digital labâ€”a space where I document technical deep dives, code snippets, and analytical explorations into algorithmic trading, risk modeling, data science, and the occasional offbeat problem that sparks my curiosity.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ajc327" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;ajc327" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:andycai517@gmail.com" title="E-Mail â†’ mailto:andycai517@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/31/gibbs-sampling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Andy Cai">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Efficient Corner">
      <meta itemprop="description" content="A quantitative portfolio manager passionate about dissecting complexity at the intersection of finance, math, and technology. This site is my digital labâ€”a space where I document technical deep dives, code snippets, and analytical explorations into algorithmic trading, risk modeling, data science, and the occasional offbeat problem that sparks my curiosity.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Gibbs Sampling | Efficient Corner">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Gibbs Sampling
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-10-31 21:49:55" itemprop="dateCreated datePublished" datetime="2020-10-31T21:49:55+08:00">2020-10-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-04-04 10:15:41" itemprop="dateModified" datetime="2025-04-04T10:15:41+08:00">2025-04-04</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>In many inference tasks, it is necessary to integrate out variables. However, this may not always be possible as the integral may not be an analytically trackable function. Thankfully, we can leverage the law of large numbers to estimate these integrals from sampling. This means if we want to estimate $\phi &#x3D; \int \phi(x) p(x) dx$, we can simply sample from the joint distribution $p(x)$. We can take the empirical average $ \frac{1}{N} \sum_{i&#x3D;1}^N \phi(x_i)$, for large enough N this would converge to the actual mean. The problem is that the form of $ p(x) $ may be undesirable and sampling can be made difficult. One method to deal with this problem is using Gibbs sampling, which samples from the conditional distribution instead.</p>
<h2 id="Gibbs-Sampling-method"><a href="#Gibbs-Sampling-method" class="headerlink" title="Gibbs Sampling method"></a>Gibbs Sampling method</h2><p>For each component i of x in turn, sample a new value from the conditional distribution of $x_i$ given all other $x_{j\neq i}$:  </p>
<p>$$\begin{align}<br>x_i &amp; \sim p(x_i|x1,â€¦,x_{i-1},x{i+1},â€¦,x_D)<br>\end{align} $$</p>
<p>This eventually generates dependent samples from the joint distribution $p(x)$.</p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><p>In this notebook I implement a Gibbs sampler, for both 2D and 3D distributions. This has taken inspiration from the materials in the Cambridge University Probablistic Machine Learning Course.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tools <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> scipy.linalg <span class="keyword">import</span> sqrtm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<h2 id="Function-to-visualise-a-Guassian-with-a-given-variance"><a href="#Function-to-visualise-a-Guassian-with-a-given-variance" class="headerlink" title="Function to visualise a Guassian with a given variance"></a>Function to visualise a Guassian with a given variance</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_gaussian</span>(<span class="params">cov,mu,n,ax</span>):</span><br><span class="line">    mu = np.reshape(a=mu, newshape=(<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">    theta = np.divide(<span class="built_in">range</span>(n),(n-<span class="number">1</span>))*<span class="number">2</span>*np.pi</span><br><span class="line">    epoints = np.matmul(sqrtm(cov),[np.cos(theta),np.sin(theta)])</span><br><span class="line">    epoints += np.matmul(mu, np.ones((<span class="number">1</span>,n)))</span><br><span class="line">    ax.plot(epoints[<span class="number">0</span>,:],epoints[<span class="number">1</span>,:])</span><br><span class="line">    ax.scatter(mu[<span class="number">0</span>,:],mu[<span class="number">1</span>,:],c =<span class="string">&#x27;r&#x27;</span>, s=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">plot_gaussian([[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]],[<span class="number">1</span>,<span class="number">1</span>],<span class="number">60</span>, ax= ax)</span><br></pre></td></tr></table></figure>
<p><img data-src="/images/gibbs_1.png" title="Gaussian function"></p>
<h2 id="The-Gibbs-sampler-to-sample-from-the-2D-Gaussian"><a href="#The-Gibbs-sampler-to-sample-from-the-2D-Gaussian" class="headerlink" title="The Gibbs sampler to sample from the 2D Gaussian"></a>The Gibbs sampler to sample from the 2D Gaussian</h2><p>This function first plots the joint Gaussian distribution on the random walk axes, using the previously defined function. This allows the target distribution to be visualised.</p>
<p>The gibbs2 function then iterates throught the number of iterations require. For each iteration, it computes the conditional distribution of x given y, and vice versa. These give $p(x|y)$ and $p(y|x)$ to sample from. The conditionals are obtained by segmenting the covariance matrix in to sub matrices</p>
<p>\begin{align}<br>p(x,y) &amp; &#x3D; \mathcal{N}\left( \begin{bmatrix} a \ b \end{bmatrix}, \begin{bmatrix} A &amp; B \ B^T &amp; C \end{bmatrix}\right) \<br>&amp; \to \<br>p(x|y) &amp; &#x3D; \mathcal{N}(a+BC^{-1}(y-b), A-BC^{-1}B^T)<br>\end{align}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gibbs2</span>(<span class="params">N, ax1,ax2,cov=[[<span class="number">1</span>, <span class="number">0.5</span>],[<span class="number">0.5</span>,<span class="number">1</span>]], m =[<span class="number">0</span>,<span class="number">0</span>]</span>):</span><br><span class="line">    cov = np.array(cov)</span><br><span class="line">    ci = np.linalg.inv(cov)</span><br><span class="line">    <span class="comment"># init x at -2,2 </span></span><br><span class="line">    x = -<span class="number">2</span></span><br><span class="line">    y = <span class="number">2</span></span><br><span class="line">    plot_gaussian(cov=<span class="number">4</span>*cov, ax=ax1,mu=m,n=<span class="number">300</span>)</span><br><span class="line">    xx=[x]</span><br><span class="line">    yy=[y]</span><br><span class="line"></span><br><span class="line">    diff_list =[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        xold = x</span><br><span class="line">        yold = y</span><br><span class="line">        x= -ci[<span class="number">0</span>,<span class="number">1</span>]*y/ci[<span class="number">0</span>,<span class="number">0</span>] + np.random.randn()/np.sqrt(ci[<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line">        <span class="comment">#print([xold,x])</span></span><br><span class="line">        ax1.plot([xold,x],[yold,y])</span><br><span class="line">        xold = x;</span><br><span class="line">        y = -ci[<span class="number">0</span>,<span class="number">1</span>]*x/ci[<span class="number">1</span>,<span class="number">1</span>]+ np.random.randn()/np.sqrt(ci[<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(xx)&gt;<span class="number">1</span>:</span><br><span class="line">            emp_cov = np.cov(np.array(xx),np.array(yy))</span><br><span class="line">            diff = -<span class="built_in">abs</span>(cov-emp_cov).<span class="built_in">sum</span>()</span><br><span class="line">            diff_list.append(diff)</span><br><span class="line">            ax2.clear()</span><br><span class="line">            ax2.plot(diff_list)</span><br><span class="line">            ax2.set_title(<span class="string">&#x27;Convergence plot&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            ax2.set_xlabel(<span class="string">&#x27;iterations&#x27;</span>)</span><br><span class="line">            ax2.set_ylabel(<span class="string">&#x27;Empirical Covariance Matrix Error&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        ax1.plot([xold,x],[yold,y])</span><br><span class="line">        ax1.scatter(x,y, s= <span class="number">30</span>)</span><br><span class="line">        xx.append(x)</span><br><span class="line">        yy.append(y)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Uncomment this section and set %matplotlib to none to see live plot</span></span><br><span class="line">        <span class="comment">#plt.draw()</span></span><br><span class="line">        <span class="comment">#if i ==0:</span></span><br><span class="line">            <span class="comment">#plt.pause(0.1)</span></span><br><span class="line">        <span class="comment">#plt.pause(0.005)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">ax1= plt.subplot(<span class="number">211</span>)</span><br><span class="line">fig.suptitle(<span class="string">&#x27;Gibbs Sampling process on a 2D Gaussian distribution and Convergence plot&#x27;</span>,fontsize=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Markov Chain Random Walk&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2= plt.subplot(<span class="number">212</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Convergence plot&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;iterations&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.ion()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#ani = animation.FuncAnimation(figs,animate, interval=1000)</span></span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line">gibbs2(<span class="number">100</span>,ax1,ax2)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img data-src="/images/gibbs_2.png"></p>
<h2 id="Function-to-sample-from-the-3-dimensional-Gaussian"><a href="#Function-to-sample-from-the-3-dimensional-Gaussian" class="headerlink" title="Function to sample from the 3 dimensional Gaussian"></a>Function to sample from the 3 dimensional Gaussian</h2><p>For the trivariate Guassian, the conditionals are more tricky to compute, as in the 2D case the conditional probability equations boil down to a set of scalars, where as in this case we see that matrices $A,B,C$ are matrices. We use a for loop to generate these matrices when we look at each of the variables [x1,x2,x3].</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gibbs3</span>(<span class="params">N, ax1,ax,cov=[[<span class="number">1</span>, <span class="number">0.5</span>,<span class="number">0.3</span>],[<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">0.2</span>],[<span class="number">0.3</span>,<span class="number">0.2</span>,<span class="number">1</span>]], mu =[<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>]</span>):</span><br><span class="line">    cov = np.array(cov)</span><br><span class="line">    <span class="comment"># init x at -2,2 </span></span><br><span class="line">    x = np.array([-<span class="number">2.0</span>,<span class="number">2.0</span>,<span class="number">2.0</span>])</span><br><span class="line">    mu = np.array(mu)</span><br><span class="line">    xx=np.array([[],[],[]])</span><br><span class="line">    diff_list=[]</span><br><span class="line">    xold=[<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>]</span><br><span class="line">    xold[<span class="number">0</span>]= x[<span class="number">0</span>]</span><br><span class="line">    xold[<span class="number">1</span>]=x[<span class="number">1</span>]</span><br><span class="line">    xold[<span class="number">2</span>]=x[<span class="number">2</span>]</span><br><span class="line">    ite=[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            ind_list = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">            ind_list.remove(j)</span><br><span class="line">            B=np.array([cov[j,ind_list[<span class="number">0</span>]],cov[j,ind_list[<span class="number">1</span>]]])</span><br><span class="line">            C=np.array([[cov[ind_list[<span class="number">0</span>],ind_list[<span class="number">0</span>]],cov[ind_list[<span class="number">0</span>],ind_list[<span class="number">1</span>]]],[cov[ind_list[<span class="number">1</span>],ind_list[<span class="number">0</span>]],cov[ind_list[<span class="number">1</span>],ind_list[<span class="number">1</span>]]]])</span><br><span class="line">            Ci = np.linalg.inv(C)</span><br><span class="line">            D = np.array(np.subtract([x[k] <span class="keyword">for</span> k <span class="keyword">in</span> ind_list],[mu[k] <span class="keyword">for</span> k <span class="keyword">in</span> ind_list]))</span><br><span class="line">            mean= mu[j]+np.matmul(np.matmul(B,Ci),D) </span><br><span class="line">            dev = np.sqrt(cov[j,j]-np.matmul(np.matmul(B,Ci),B.T))</span><br><span class="line">            x[j] =<span class="built_in">float</span>(mean)+np.random.randn()/<span class="built_in">float</span>(dev)</span><br><span class="line"></span><br><span class="line">            ax1.plot([xold[<span class="number">0</span>],x[<span class="number">0</span>]],[xold[<span class="number">1</span>],x[<span class="number">1</span>]],[xold[<span class="number">2</span>],x[<span class="number">2</span>]],alpha = <span class="number">0.3</span>)</span><br><span class="line">            ax1.scatter(*x,s=<span class="number">20</span>,alpha=<span class="number">0.4</span>)</span><br><span class="line">            xx=np.concatenate((xx,np.reshape(x.T,(<span class="number">3</span>,<span class="number">1</span>))), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            xold[j]=x[j]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(xx[<span class="number">0</span>])&gt;<span class="number">3</span> <span class="keyword">and</span> <span class="built_in">len</span>(xx[<span class="number">0</span>])%<span class="number">8</span>==<span class="number">1</span>:</span><br><span class="line">                emp_cov = np.cov(np.array(xx))</span><br><span class="line">                diff = <span class="built_in">abs</span>(cov-emp_cov).<span class="built_in">sum</span>()</span><br><span class="line">                diff_list.append(diff)</span><br><span class="line">                ax.clear()</span><br><span class="line">                ax.plot(ite,diff_list)</span><br><span class="line">                ax.set_title(<span class="string">&#x27;Convergence Plot&#x27;</span>)</span><br><span class="line">                ax.set_ylabel(<span class="string">&#x27;Covariance matrix absolute error&#x27;</span>)</span><br><span class="line">                ax.set_xlabel(<span class="string">&#x27;Iteration&#x27;</span>)</span><br><span class="line">                ite.append(ite[-<span class="number">1</span>]+<span class="number">8</span>)</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">14</span>,<span class="number">5</span>))</span><br><span class="line">ax1= plt.subplot(<span class="number">121</span>,projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Markov Chain Monte Carlo Random Walk on trivariate Gaussian&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">ax1.set_zlabel(<span class="string">&#x27;x3&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax=plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Convergence Plot&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Covariance matrix absolute error&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Iteration&#x27;</span>)</span><br><span class="line">plt.ion()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#ani = animation.FuncAnimation(figs,animate, interval=1000)</span></span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line">gibbs3(<span class="number">300</span>,ax1,ax)</span><br></pre></td></tr></table></figure>

<p><img data-src="/images/gibbs_3.png"></p>
<h2 id="Interpretation-of-results-and-conclusion"><a href="#Interpretation-of-results-and-conclusion" class="headerlink" title="Interpretation of results and conclusion"></a>Interpretation of results and conclusion</h2><p>The gibbs sampler was able to successfully sample from the 2D and 3D distributions. It was observed that for the 2D case, the algorithm very rapidly converged in under 50 iterations. This means the variance of the sampled data was able to rapidly become similar to the expected distribution. However, for the 3D case, very slow convergence behaviour has been observed. The reason for this is currently unclear, and could be a consequence of how the convergence is defined.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Data-science/" rel="tag"># Data science</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/08/26/hacking-growth/" rel="prev" title="Hacking Growth Notes">
                  <i class="fa fa-angle-left"></i> Hacking Growth Notes
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/25/linux-remote/" rel="next" title="Linux Remote Development">
                  Linux Remote Development <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Andy Cai</span>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/ajc327" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>



</body>
</html>
